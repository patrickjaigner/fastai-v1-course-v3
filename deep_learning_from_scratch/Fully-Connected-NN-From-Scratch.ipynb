{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11caf3b90>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Forward Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 5 # numer of examples\n",
    "n = 3 # feature size\n",
    "nh = 10 # hidden features\n",
    "\n",
    "\n",
    "\n",
    "A = torch.ones(n,nh)\n",
    "b = torch.ones(m,1)*0.5\n",
    "x = torch.ones(m,n)*0.5\n",
    "\n",
    "target = torch.ones(m,1)*4\n",
    "\n",
    "# torch.randn\n",
    "# torch.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear\n",
    "def lin(x,A,b): return x@A + b    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin(x,A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lin with Einsum\n",
    "def lin_es(x,A,b): return torch.einsum('ik,kj->ij',x,A) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_es(x,A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relu\n",
    "def relu(x): return torch.clamp(x,min=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Msi\n",
    "def mse(y, y_hat): return ((y - y_hat)**2).sum() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.ones(5,1)*3\n",
    "y_hat = torch.ones(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Backward Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_grad(inp, out):\n",
    "    # 2*(y-y_hat).sum() /n\n",
    "    inp.g = (2. * (inp - out)) / len(inp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_grad(inp, out): \n",
    "    inp.g = (inp>0).float() * out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_grad(inp,out,A,b):\n",
    "    inp.g = out.g @ A.t()\n",
    "    A.g = inp.t() @ out.g \n",
    "    b.g = out.g.sum(1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Forward Backward Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 20 # numer of examples\n",
    "n = 5 # feature size\n",
    "nh = 10 # hidden features\n",
    "\n",
    "x = torch.randn(m,n)\n",
    "target = torch.randn(m,1)\n",
    "\n",
    "W1 = torch.randn(n, nh)\n",
    "b1 = torch.randn(m,1)\n",
    "W2 = torch.randn(nh,1)\n",
    "b2 = torch.randn(m,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 5])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = lin_es(x,W1,b1) # m x nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = relu(l1) # m x nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lin_es(l2,W2,b2) # m x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_grad(y, target) # m x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "print(y.g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_grad(l2,y,W2,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 10])\n"
     ]
    }
   ],
   "source": [
    "print(l2.g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_grad(l1,l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 10])\n"
     ]
    }
   ],
   "source": [
    "print(l1.g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_grad(x,l1,W1,b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 5])\n"
     ]
    }
   ],
   "source": [
    "print(x.g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(inp, targ):\n",
    "    # forward pass:\n",
    "    l1 = lin_es(inp,W1,b1)\n",
    "    l2 = relu(l1)\n",
    "    out = lin_es(l2,W2,b2)\n",
    "    loss = mse(out, targ)\n",
    "    print(loss)\n",
    "    \n",
    "    # backward pass:\n",
    "    mse_grad(out, targ)\n",
    "    lin_grad(l2, out, W2, b2)\n",
    "    relu_grad(l1, l2)\n",
    "    lin_grad(inp, l1, W1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19.7892)\n"
     ]
    }
   ],
   "source": [
    "forward_and_backward(x, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for testing against later\n",
    "w1g = W1.g.clone()\n",
    "w2g = W2.g.clone()\n",
    "b1g = b1.g.clone()\n",
    "b2g = b2.g.clone()\n",
    "ig  = x.g.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with Pytorch to check implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt2 = x.clone().requires_grad_(True)\n",
    "w12 = W1.clone().requires_grad_(True)\n",
    "w22 = W2.clone().requires_grad_(True)\n",
    "b12 = b1.clone().requires_grad_(True)\n",
    "b22 = b2.clone().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(inp, targ):\n",
    "    # forward pass:\n",
    "    l1 = inp @ w12 + b12\n",
    "    l2 = relu(l1)\n",
    "    out = l2 @ w22 + b22\n",
    "    # we don't actually need the loss in backward!\n",
    "    return mse(out, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19.7892, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = forward(xt2, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_near(a,b,tol=1e-3):\n",
    "    assert (a-b).abs().max() < tol, f\"Not near zero\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(w22.grad, w2g)\n",
    "test_near(b22.grad, b2g)\n",
    "test_near(w12.grad, w1g)\n",
    "test_near(b12.grad, b1g)\n",
    "test_near(xt2.grad, ig )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Refactoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module():\n",
    "    \"\"\"This holds the basic functions of layer classes\"\"\"\n",
    "    \n",
    "    def __call__(self, *args):\n",
    "        self.args = args\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "\n",
    "    def forward(self):\n",
    "        raise Exception('Not implemented')\n",
    "        \n",
    "    def backward(self): \n",
    "        self._backward(self.out, *self.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mse(Module):\n",
    "    \"\"\"Mse activation layer for Neural Networks\"\"\"\n",
    "          \n",
    "    def forward(self, inp, target):\n",
    "        self.loss = ((inp - target)**2).sum() / len(inp)\n",
    "        return self.loss\n",
    "    \n",
    "    def _backward(self, out, inp, target): \n",
    "        inp.g = (2. * (inp - target)) / len(inp)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.ones(20,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3912)\n"
     ]
    }
   ],
   "source": [
    "loss = Mse()\n",
    "loss_model = loss(y,target)\n",
    "print(loss_model)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0037],\n",
       "        [ 0.0651],\n",
       "        [ 0.1921],\n",
       "        [ 0.1056],\n",
       "        [-0.0140]])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.g[:5] # internal value for gradient is passed to input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0037],\n",
       "        [ 0.0651],\n",
       "        [ 0.1921],\n",
       "        [ 0.1056],\n",
       "        [-0.0140]])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.args[0].g[:5] # internal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.g = torch.ones(20,1)\n",
    "loss.args[0].g[:5] # also changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin(Module):\n",
    "    \"\"\"Linear Layer for Neural Networks\"\"\"\n",
    "    \n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        return torch.einsum('ik,kj->ij',inp, self.W) + self.b\n",
    "    \n",
    "    def _backward(self, out, inp):\n",
    "        inp.g = out.g @ self.W.t()\n",
    "        self.W.g = inp.t() @ out.g \n",
    "        self.b.g = out.g.sum(1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lin_1 = Lin(W1,b1)\n",
    "out = Lin_1(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu(Module):\n",
    "    \"Relu actication layer for Neural Networks\"\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        return torch.clamp(inp,min=0.)\n",
    "    \n",
    "    def _backward(self, out, inp):\n",
    "        inp.g = (inp>0).float() * out.g\n",
    "        return inp.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets test our model\n",
    "\n",
    "l1 = Lin(W1,b1)\n",
    "l2 = Relu()\n",
    "l3 = Lin(W2,b2)\n",
    "loss = Mse()\n",
    "\n",
    "out = l1(x)\n",
    "out = l2(out)\n",
    "out = l3(out)\n",
    "out = loss(out, target)\n",
    "\n",
    "loss.backward()\n",
    "l3.backward()\n",
    "l2.backward()\n",
    "l1.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_w1g = l1.W.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactoring was successful, if no error is raised\n",
    "test_near(w12.grad, class_w1g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.layers = [Lin(W1,b1), Relu(), Lin(W2,b2)]\n",
    "        self.loss = Mse()\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return self.loss(x, targ)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers): l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "loss = model(x, target)\n",
    "model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w1g = model.layers[0].W.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactoring was successful, if no error is raised\n",
    "test_near(w12.grad, model_w1g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
