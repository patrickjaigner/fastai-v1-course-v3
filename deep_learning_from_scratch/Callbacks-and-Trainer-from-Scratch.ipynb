{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal is to implement callbacks to allow inserting different operations during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a dataset to train\n",
    "from fastai import datasets\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'\n",
    "\n",
    "def get_data():\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(torch.tensor, (x_train,y_train,x_valid,y_valid))\n",
    "\n",
    "x_train,y_train,x_valid,y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 784]),\n",
       " torch.Size([50000]),\n",
       " torch.Size([10000, 784]),\n",
       " torch.Size([10000]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Dataset(Dataset):\n",
    "    \"\"\"This class holds and resizes MNIST datasets.\"\"\"\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x = self.mnist_resize(x)\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "            return self.x[i], self.y[i]  \n",
    "        \n",
    "    def mnist_resize(self,x):\n",
    "        return x.view(-1,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = MNIST_Dataset(x_train,y_train)\n",
    "ds_valid = MNIST_Dataset(x_valid,y_valid)\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=64, shuffle=True)\n",
    "dl_valid = DataLoader(ds_valid, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    \"\"\"This class 'simulates' a Pytorch nn layern and allows to insert functions with\n",
    "    a single input and single output.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    return x.view(x.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_flatten = flatten(torch.Tensor(100,32,1,1))\n",
    "x_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.1)\n",
       "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.1)\n",
       "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.1)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.1)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (4): AdaptiveAvgPool2d(output_size=1)\n",
       "  (5): Lambda()\n",
       "  (6): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 64\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Sequential(nn.Conv2d(1, 8, 5, stride=2, padding=2), \n",
    "                          nn.LeakyReLU(negative_slope=0.1),\n",
    "                          nn.BatchNorm2d(8)), #14\n",
    "            nn.Sequential(nn.Conv2d(8, 16, 3, stride=1, padding=2),\n",
    "                          nn.LeakyReLU(negative_slope=0.1),\n",
    "                          nn.BatchNorm2d(16)), #7\n",
    "            nn.Sequential(nn.Conv2d(16, 32, 3, stride=1, padding=2),\n",
    "                          nn.LeakyReLU(negative_slope=0.1),\n",
    "                          nn.BatchNorm2d(32)), #4\n",
    "            nn.Sequential(nn.Conv2d(32, 32, 3, stride=1, padding=2),\n",
    "                          nn.LeakyReLU(negative_slope=0.1),\n",
    "                          nn.BatchNorm2d(32)), #2\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            Lambda(flatten),\n",
    "            nn.Linear(32,10)\n",
    "        )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the random weights with Kaiming\n",
    "for l in model:\n",
    "    if isinstance(l, nn.Sequential):\n",
    "        nn.init.kaiming_normal_(l[0].weight)\n",
    "        l[0].bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    \"\"\"This class holds the expected structure for callbacks and shall be inherited from \n",
    "    other custom callbacks. To stop execution early different Exceptions are available \n",
    "    that can be raised. These exceptions shall be caught by the main training loop.\n",
    "    \"\"\"\n",
    "    \n",
    "    def set_trainer(self, train): \n",
    "        self.train=train\n",
    "    \n",
    "    def begin_training(self): pass\n",
    "    \n",
    "    def after_training(self): pass\n",
    "    \n",
    "    def cancel_training(self): pass\n",
    "    \n",
    "    def begin_epoch(self): pass\n",
    "    \n",
    "    def after_epoch(self): pass\n",
    "    \n",
    "    def cancel_epoch(self): pass\n",
    "    \n",
    "    def begin_batch(self): pass\n",
    "    \n",
    "    def after_batch(self): pass\n",
    "    \n",
    "    def cancel_batch(self): pass\n",
    "    \n",
    "    def after_pred(self): pass\n",
    "    \n",
    "    def after_loss(self): pass\n",
    "    \n",
    "    def after_backward(self): pass\n",
    "    \n",
    "    def after_step(self): pass\n",
    "    \n",
    "    def begin_validation(self): pass\n",
    "    \n",
    "    \n",
    "class CancelTrainException(Exception): pass\n",
    "class CancelEpochException(Exception): pass\n",
    "class CancelBatchException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintAccuarcyCallback(Callback):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.acc = []\n",
    "    \n",
    "    def accuracy(self, pred, yb): \n",
    "        return (torch.argmax(pred, dim=1)==yb).float().mean()\n",
    "    \n",
    "    def begin_validation(self):\n",
    "        self.acc = []\n",
    "    \n",
    "    def after_pred(self):\n",
    "        self.acc.append(self.accuracy(self.train.pred, self.train.yb).item())\n",
    "        \n",
    "    def after_epoch(self):\n",
    "        mean_acc = sum(self.acc) / len(self.acc)\n",
    "        \n",
    "        print(f'The validation accuracy for epoch {self.train.epoch+1} is: {mean_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancelMidEpochCallback(Callback):\n",
    "    \n",
    "    def after_batch(self):\n",
    "        print(self.train.batch)\n",
    "        if self.train.batch >= 20:\n",
    "            raise CancelTrainException\n",
    "            \n",
    "    def cancel_training(self):\n",
    "        print('Canceled Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    \"\"\"This class initializes a train that can be called with n epochs to run.\n",
    "    It needs following input:\n",
    "    model: A Pytorch nn.Module\n",
    "    dl_train: A Pytorch DataLoader\n",
    "    dl_valid: A Pytorch DataLoader\n",
    "    optimizer: A Pytorch optimizer functipon\n",
    "    loss_func: A Pytorch loss function\n",
    "    callbacks: A list of Callback Class Instances\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, dl_train, dl_valid, optimizer, loss_func, callbacks):\n",
    "        self.model = model\n",
    "        self.dl_train, self.dl_valid = dl_train, dl_valid\n",
    "        self.opt = optimizer\n",
    "        self.loss_func = loss_func\n",
    "        self.cbs = callbacks\n",
    "        self.valid_mode = False\n",
    "        \n",
    "        for cb in self.cbs:\n",
    "            cb.set_trainer(self)\n",
    "            \n",
    "    def _run_one_batch(self, xb, yb):\n",
    "        \n",
    "        try:\n",
    "            for cb in self.cbs: cb.begin_batch()                 # Begin Batch\n",
    "\n",
    "            self.pred = self.model(xb)\n",
    "            for cb in self.cbs: cb.after_pred()                  # After Pred\n",
    "            self.loss = self.loss_func(self.pred,yb)\n",
    "            for cb in self.cbs: cb.after_loss()                  # After Loss\n",
    "            if self.valid_mode: return\n",
    "            self.loss.backward()\n",
    "            for cb in self.cbs: cb.after_backward()              # After Backward\n",
    "                \n",
    "            self.opt.step()\n",
    "            for cb in self.cbs: cb.after_step()                  # After Step \n",
    "            self.opt.zero_grad()\n",
    "\n",
    "            for cb in self.cbs: cb.after_batch()                 # After Batch\n",
    "                \n",
    "        except CancelBatchException: \n",
    "            for cb in self.cbs: cb.cancel_batch()                # Cancel Batch\n",
    "    \n",
    "    def _run_one_epoch(self, dl):\n",
    "        self.batch = 1\n",
    "        try:\n",
    "            for xb, yb in dl:\n",
    "                self.xb, self.yb = xb, yb\n",
    "\n",
    "                self._run_one_batch(xb, yb)\n",
    "                self.batch += 1\n",
    "                 \n",
    "        except CancelEpochException:\n",
    "            for cb in self.cbs: cb.cancel_epoch()               # Cancel Epoch\n",
    "              \n",
    "    def __call__(self, epochs):\n",
    "        for cb in self.cbs: cb.begin_training()                 # Begin Training\n",
    "        try:\n",
    "            for epoch in range(epochs):\n",
    "                self.epoch = epoch\n",
    "                for cb in self.cbs: cb.begin_epoch()            # Begin Epoch\n",
    "                self._run_one_epoch(dl_train)\n",
    "                            \n",
    "                with torch.no_grad():\n",
    "                    for cb in self.cbs: cb.begin_validation()   # Begin Validation\n",
    "                    self.valid_mode = True\n",
    "                    self._run_one_epoch(dl_valid)\n",
    "                    self.valid_mode = False\n",
    "\n",
    "                for cb in self.cbs: cb.after_epoch()            # After Epoch\n",
    "                \n",
    "                \n",
    "                \n",
    "        except CancelTrainException:\n",
    "            for cb in self.cbs: cb.cancel_training()            # Cancel Training\n",
    "                \n",
    "        for cb in self.cbs: cb.after_training()                 # After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "loss_func = F.cross_entropy\n",
    "cbs = [PrintAccuarcyCallback()]\n",
    "\n",
    "train = Trainer(model, dl_train, dl_valid, opt, loss_func, cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy for epoch 1 is: 0.9170\n",
      "The validation accuracy for epoch 2 is: 0.9580\n",
      "The validation accuracy for epoch 3 is: 0.9695\n"
     ]
    }
   ],
   "source": [
    "train(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "loss_func = F.cross_entropy\n",
    "cbs = [PrintAccuarcyCallback(), CancelMidEpochCallback()]\n",
    "\n",
    "train = Trainer(model, dl_train, dl_valid, opt, loss_func, cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "Canceled Training\n"
     ]
    }
   ],
   "source": [
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
